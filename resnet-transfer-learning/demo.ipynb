{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with ResNet34 on CIFAR-10\n",
        "\n",
        "This notebook demonstrates transfer learning using a pretrained ResNet34 model on the CIFAR-10 dataset. We explore two common approaches:\n",
        "\n",
        "- **Feature Extraction:** Freeze the pretrained base layers and train only the final classifier.\n",
        "- **Fine Tuning:** Train the entire model, updating all weights.\n",
        "\n",
        "---\n",
        "\n",
        "## Setup and Imports\n"
      ],
      "metadata": {
        "id": "1nxopYwoe2GY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from resnet_models import initialize_resnet34\n",
        "from dataloader_generator import get_dataloaders\n",
        "from utils import train_model, plot_loss_accuracy, plot_confusion_matrix, plot_predictions\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "id": "JuUrxvn8e4id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load CIFAR-10 Data\n",
        "\n",
        "We use standard transforms for training and validation data with normalization and data augmentation on training.\n"
      ],
      "metadata": {
        "id": "CgtsEJUYfCrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "train_dl, valid_dl, class_names_dict = get_dataloaders(batch_size=batch_size)\n",
        "print(f\"Number of classes: {len(class_names_dict)}\")\n"
      ],
      "metadata": {
        "id": "s3p4WTxhfGml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize ResNet34 Model\n",
        "\n",
        "We initialize the pretrained ResNet34 model and modify the final fully connected layer to match CIFAR-10 classes.\n"
      ],
      "metadata": {
        "id": "qwmzs4KhfODd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names_dict)\n",
        "model_fe = initialize_resnet34(num_classes=num_classes, pretrained=True)\n",
        "model_fe.to(device)\n",
        "model_ft = copy.deepcopy(model_fe)"
      ],
      "metadata": {
        "id": "MYzjCYSUfQqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning: Feature Extraction\n",
        "\n",
        "Freeze base layers and train only the final fully connected layer.\n"
      ],
      "metadata": {
        "id": "wF0faz16fZa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer_fe = torch.optim.Adam(model_fe.fc.parameters(), lr=1e-4)\n",
        "num_epochs = 25\n",
        "\n",
        "# Freeze base layers\n",
        "for param in model_fe.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model_fe.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Train model\n",
        "train_loss_fe, train_acc_fe, valid_loss_fe, valid_acc_fe = train_model(\n",
        "    model_fe, train_dl, valid_dl, loss_fn, optimizer_fe, num_epochs, device\n",
        ")\n",
        "\n",
        "plot_loss_accuracy(\n",
        "    {\"train_loss\": train_loss_fe, \"valid_loss\": valid_loss_fe},\n",
        "    {\"train_accu\": train_acc_fe, \"valid_accu\": valid_acc_fe}\n",
        ")\n"
      ],
      "metadata": {
        "id": "28S3yIu3fa2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix and Predictions for Feature Extraction Model\n"
      ],
      "metadata": {
        "id": "PuTV5B60fhrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(model_fe, valid_dl, class_names_dict, device)\n",
        "plot_predictions(model_fe, train_dl, class_names_dict, device)\n"
      ],
      "metadata": {
        "id": "J71u_YjbfnL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning: Fine Tuning\n",
        "\n",
        "Now, we train the entire ResNet34 model, updating all weights.\n"
      ],
      "metadata": {
        "id": "HVw-rVjVftLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_ft = torch.optim.Adam(model_ft.parameters(), lr=1e-4)\n",
        "\n",
        "# Train model (all layers trainable)\n",
        "train_loss_ft, train_acc_ft, valid_loss_ft, valid_acc_ft = train_model(\n",
        "    model_ft, train_dl, valid_dl, loss_fn, optimizer_ft, num_epochs, device\n",
        ")\n",
        "\n",
        "plot_loss_accuracy(\n",
        "    {\"train_loss\": train_loss_ft, \"valid_loss\": valid_loss_ft},\n",
        "    {\"train_accu\": train_acc_ft, \"valid_accu\": valid_acc_ft}\n",
        ")\n"
      ],
      "metadata": {
        "id": "wUqiiOS_fuqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix and Predictions for Fine-Tuned Model\n"
      ],
      "metadata": {
        "id": "K-T86U-Tf0YL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(model_ft, valid_dl, class_names_dict, device)\n",
        "plot_predictions(model_ft, train_dl, class_names_dict, device)\n"
      ],
      "metadata": {
        "id": "jQQhNnlFf18X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "- **Feature Extraction** is faster to train and requires fewer parameters to update, but may achieve slightly lower accuracy.\n",
        "- **Fine Tuning** typically yields better accuracy by adapting all layers but is computationally more intensive.\n",
        "\n",
        "In this experiment, fine tuning improved validation accuracy significantly compared to feature extraction.\n",
        "\n",
        "Both approaches are useful depending on the compute resources available and specific use case. Transfer learning leverages pretrained weights effectively, providing a strong baseline compared to training from scratch.\n",
        "\n",
        "---\n",
        "\n",
        "You can further explore hyperparameter tuning, other architectures, or custom datasets to extend this project.\n"
      ],
      "metadata": {
        "id": "YhfIW52Rf4Lg"
      }
    }
  ]
}