{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR-10 Classification with Pre-activation ResNet (resnetx_cifar10)\n",
        "\n",
        "Welcome to the demo notebook for the `resnetx_cifar10` project! In this notebook, we'll walk through:\n",
        "\n",
        "- Loading CIFAR-10 dataset\n",
        "- Training a custom Pre-activation ResNet (ResNet v2 style)\n",
        "- Visualizing training progress\n",
        "- Displaying confusion matrix and prediction samples\n",
        "- Drawing insights from results\n",
        "\n",
        "This notebook is fully modular and uses:\n",
        "- `models.py` for the architecture\n",
        "- `dataloader_generator.py` for dataset loading\n",
        "- `utils.py` for training, plotting, and evaluation\n",
        "\n",
        "> **Goal:** Achieve high accuracy on CIFAR-10 using a simplified and interpretable ResNet architecture.\n",
        "\n",
        "---\n",
        "\n",
        " Let's begin by importing necessary modules and setting up!\n"
      ],
      "metadata": {
        "id": "K_GupeI0AxMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports from standard libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Project-specific imports\n",
        "from models import PreActResNet34\n",
        "from utils import train_model, plot_confusion_matrix, plot_predictions\n",
        "from dataloader_generator import get_cifar10_dataloaders\n",
        "\n",
        "# Device configuration\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 100\n",
        "\n",
        "# Get the train and validation dataloaders + class name mapping\n",
        "train_dl, valid_dl, class_names_dict = get_cifar10_dataloaders(batch_size=batch_size)\n",
        "\n",
        "# Quick sanity check\n",
        "print(\"Train batches:\", len(train_dl))\n",
        "print(\"Validation batches:\", len(valid_dl))\n",
        "print(\"Classes:\", class_names_dict)\n",
        "\n",
        "# Device configuration\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Initialize the model and move it to device\n",
        "model = PreActResNet34().to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Training parameters\n",
        "num_epochs = 50\n",
        "\n",
        "# Train the model\n",
        "train_loss, train_acc, test_loss, test_acc = train_model(\n",
        "    model, train_dl, valid_dl, loss_fn, optimizer, num_epochs, device\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "history = {\n",
        "    'train_loss': train_loss,\n",
        "    'train_acc': train_acc,\n",
        "    'test_loss': test_loss,\n",
        "    'test_acc': test_acc\n",
        "}\n",
        "pd.DataFrame(history).plot(figsize=(10,5))\n",
        "plt.title(\"Training and Validation Metrics Over Epochs\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7FyGsQT1A75t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrix on validation set\n",
        "plot_confusion_matrix(model, valid_dl, class_names_dict, device)\n",
        "\n",
        "# Plot examples of correct and incorrect predictions on training set\n",
        "plot_predictions(model, train_dl, class_names_dict, device, row=1, col=8, figsize=(15,3), max_size=20)"
      ],
      "metadata": {
        "id": "TCYuMvgcCOIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion and Next Steps\n",
        "\n",
        "- The PreActResNet34 model trained on CIFAR-10 demonstrates solid performance with good accuracy and generalization.\n",
        "- Data augmentations like random cropping, flipping, and color jittering helped improve robustness.\n",
        "- Confusion matrix and prediction plots provide insights into class-wise performance and common misclassifications.\n",
        "- Potential improvements:\n",
        "  - Experiment with learning rate schedulers or other optimizers.\n",
        "  - Try deeper variants like PreActResNet50 or 101 for potentially better accuracy.\n",
        "  - Implement early stopping or checkpointing for more efficient training.\n",
        "  - Expand to other datasets or tasks to validate model generalization.\n",
        "\n",
        "Feel free to explore and build upon this foundation!\n"
      ],
      "metadata": {
        "id": "nbpsyXg9CXeW"
      }
    }
  ]
}