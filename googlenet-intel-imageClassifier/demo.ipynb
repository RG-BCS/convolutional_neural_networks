{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GoogLeNet (Inception) for Intel Image Classification\n",
        "\n",
        "This notebook demonstrates how to train and evaluate a custom-built GoogLeNet-style model with auxiliary classifiers on the Intel Image Classification dataset using TensorFlow/Keras.\n",
        "\n",
        "## Goals\n",
        "- Build a modular, reusable Inception model\n",
        "- Train it on natural scenes from the Intel dataset\n",
        "- Use auxiliary outputs to aid convergence\n",
        "- Visualize performance with confusion matrix and predictions\n",
        "\n",
        "---\n",
        "\n",
        "## Step 1: Import Dependencies & Modules\n"
      ],
      "metadata": {
        "id": "mBZiG1NS0JbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from model import build_inception_model\n",
        "from dataset_generator import get_data_generators\n",
        "from utils import multi_output_generator, plot_confusion_matrix, plot_predictions\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n"
      ],
      "metadata": {
        "id": "9OT0RcGk0UkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Step 2: Set Paths, Parameters, and Load Data\n"
      ],
      "metadata": {
        "id": "riUN0HIM0atm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/kaggle/input/intel-image-classification/seg_train/seg_train'\n",
        "test_dir = '/kaggle/input/intel-image-classification/seg_test/seg_test'\n",
        "batch_size = 32\n",
        "image_size = (224, 224, 3)\n",
        "num_classes = 6\n",
        "epochs = 30\n",
        "\n",
        "# Load data generators and class name mapping\n",
        "train_gen, val_gen, test_gen, class_names_dict = get_data_generators(train_dir, test_dir, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "YOHw_1_30hja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Step 3: Prepare Raw Test Set for Evaluation\n",
        "We extract the full test set for early evaluation and visualization later.\n"
      ],
      "metadata": {
        "id": "E7kGhmUQ0oLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PREPARE TEST DATA ===\n",
        "X_test, y_test = next(test_gen.__class__(directory=test_dir,target_size=image_size[:2],batch_size=3000,\n",
        "                                         class_mode='sparse',shuffle=False))"
      ],
      "metadata": {
        "id": "lXBDf5Zb0nx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Step 4: Build and Compile GoogLeNet with Aux Outputs\n",
        "The model has 3 outputs: main, aux1, and aux2, trained with weighted loss.\n"
      ],
      "metadata": {
        "id": "YO7pttb-0354"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_inception_model(num_classes=num_classes, image_size=image_size)\n",
        "\n",
        "# === MODEL SETUP ===\n",
        "model = build_inception_model(num_classes=num_classes, image_size=image_size)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss=[\"sparse_categorical_crossentropy\"] * 3,loss_weights=[1.0, 0.3, 0.3],metrics=[\"accuracy\"] * 3)"
      ],
      "metadata": {
        "id": "1HX32qY107cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Step 5: Evaluate Model Before Training\n"
      ],
      "metadata": {
        "id": "VJ6lYmBG1TxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === INITIAL EVALUATION ===\n",
        "results = model.evaluate([X_test], [y_test, y_test, y_test], verbose=0)\n",
        "print(f\"\\nBefore Training Total Loss: {results[0]:.4f}\")\n",
        "print(f\"Main Output Loss: {results[1]:.4f} | Accuracy: {results[4]*100:.2f}%\")\n",
        "print(f\"Aux1 Output Loss: {results[2]:.4f} | Accuracy: {results[5]*100:.2f}%\")\n",
        "print(f\"Aux2 Output Loss: {results[3]:.4f} | Accuracy: {results[6]*100:.2f}%\\n\")\n"
      ],
      "metadata": {
        "id": "pgnF9Iq11aCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Step 6: Create TF Datasets and Train the Model\n",
        "Using `tf.data.Dataset` with a generator for multiple outputs.\n"
      ],
      "metadata": {
        "id": "ZDXBeP6n1g-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PREPARE TF DATASETS ===\n",
        "output_signature = (tf.TensorSpec(shape=(None, *image_size), dtype=tf.float32),\n",
        "                    (tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
        "                    tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
        "                    tf.TensorSpec(shape=(None,), dtype=tf.float32)))\n",
        "\n",
        "train_ds = tf.data.Dataset.from_generator(lambda: multi_output_generator(train_gen),output_signature=output_signature)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_generator(lambda: multi_output_generator(val_gen),output_signature=output_signature)\n",
        "\n",
        "# === CALLBACKS ===\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"best_inception_model.keras\", save_best_only=True),\n",
        "             keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True),\n",
        "             keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=2)]\n",
        "\n",
        "# === TRAIN MODEL ===\n",
        "history = model.fit(train_ds,validation_data=val_ds,epochs=epochs,steps_per_epoch=len(train_gen),\n",
        "                    validation_steps=len(val_gen),callbacks=callbacks)"
      ],
      "metadata": {
        "id": "nY2beOHM1lig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Step 7: Evaluate Model After Training\n"
      ],
      "metadata": {
        "id": "Rzmt578v2ZCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === FINAL EVALUATION ===\n",
        "results = model.evaluate([X_test], [y_test, y_test, y_test], verbose=0)\n",
        "print(f\"\\nAfter Training Total Loss: {results[0]:.4f}\")\n",
        "print(f\"Main Output Loss: {results[1]:.4f} | Accuracy: {results[4]*100:.2f}%\")\n",
        "print(f\"Aux1 Output Loss: {results[2]:.4f} | Accuracy: {results[5]*100:.2f}%\")\n",
        "print(f\"Aux2 Output Loss: {results[3]:.4f} | Accuracy: {results[6]*100:.2f}%\\n\")"
      ],
      "metadata": {
        "id": "FYYPwRM8yOTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Step 8: Plot Training Curves\n"
      ],
      "metadata": {
        "id": "L0MNOUP22jPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PLOT TRAINING CURVES ===\n",
        "pd.DataFrame(history.history).plot(figsize=(10, 6))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.title(\"Training History\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wo4zOiB_2k2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Step 9: Confusion Matrix\n",
        "Visualize how well the model performed across different classes.\n"
      ],
      "metadata": {
        "id": "QTalORxq2o-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PLOT CONFUSION MATRIX & SAMPLE PREDICTIONS ===\n",
        "plot_confusion_matrix(model, X_test, y_test, class_names_dict)"
      ],
      "metadata": {
        "id": "lAzR_GUo2q3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Step 10: Plot Correct & Incorrect Predictions\n"
      ],
      "metadata": {
        "id": "URES5szk2yNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(model, X_test, y_test, row=1, col=8, figsize=(15, 3), class_names_dict=class_names_dict)"
      ],
      "metadata": {
        "id": "T2spygpZ20Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "- The GoogLeNet-style model with auxiliary classifiers performed well on the Intel Image Classification dataset.\n",
        "- Confusion matrix and prediction visualizations show good performance with some class confusion.\n",
        "- Auxiliary heads helped regularize learning and improved convergence.\n",
        "- The entire pipeline is modular and reusable for other classification tasks.\n",
        "\n",
        "You can now plug in different datasets, adjust `num_classes`, or use this as a foundation for transfer learning or custom training loops.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "TVSVZwUW3WCi"
      }
    }
  ]
}